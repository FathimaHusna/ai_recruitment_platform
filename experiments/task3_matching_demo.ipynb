{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe4aafc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import json\n",
    "import io\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Any, Optional, Tuple\n",
    "import re\n",
    "import openai\n",
    "from pymongo import MongoClient\n",
    "import PyPDF2\n",
    "import docx\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "from dataclasses import dataclass\n",
    "import logging\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle\n",
    "from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
    "from reportlab.lib import colors\n",
    "from reportlab.lib.units import inch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e8d2c56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load environment variables\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643d63c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d59ac59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "59bd783b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ProcessedResume:\n",
    "    \"\"\"Data class for processed resume information\"\"\"\n",
    "    name: str\n",
    "    email: str\n",
    "    phone: str\n",
    "    location: str\n",
    "    summary: str\n",
    "    experience_years: str\n",
    "    education: List[str]\n",
    "    technical_skills: List[str]\n",
    "    soft_skills: List[str]\n",
    "    work_experience: List[str]\n",
    "    certifications: List[str]\n",
    "    keywords: List[str]\n",
    "    resume_text: str\n",
    "    processed_at: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "24882b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class JobMatch:\n",
    "    \"\"\"Data class for job matching results\"\"\"\n",
    "    job_id: str\n",
    "    title: str\n",
    "    category: str\n",
    "    company_type: str\n",
    "    location: str\n",
    "    similarity_score: float\n",
    "    matching_skills: List[str]\n",
    "    missing_skills: List[str]\n",
    "    job_summary: str\n",
    "    salary_range: str\n",
    "    match_reasons: List[str]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5c425776",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResumeProcessor:\n",
    "    \"\"\"Handle resume file processing and text extraction\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def extract_text_from_pdf(file) -> str:\n",
    "        \"\"\"Extract text from PDF file\"\"\"\n",
    "        try:\n",
    "            pdf_reader = PyPDF2.PdfReader(file)\n",
    "            text = \"\"\n",
    "            for page in pdf_reader.pages:\n",
    "                text += page.extract_text() + \"\\n\"\n",
    "            return text\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error extracting PDF text: {e}\")\n",
    "            return \"\"\n",
    "    @staticmethod\n",
    "    def extract_text_from_docx(file) -> str:\n",
    "        \"\"\"Extract text from DOCX file\"\"\"\n",
    "        try:\n",
    "            doc = docx.Document(file)\n",
    "            text = \"\"\n",
    "            for paragraph in doc.paragraphs:\n",
    "                text += paragraph.text + \"\\n\"\n",
    "            return text\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error extracting DOCX text: {e}\")\n",
    "            return \"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def extract_text_from_txt(file) -> str:\n",
    "        \"\"\"Extract text from TXT file\"\"\"\n",
    "        try:\n",
    "            return file.read().decode('utf-8')\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error extracting TXT text: {e}\")\n",
    "            return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "84b6b13d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fathima Husna\n",
      "♂¶ap-¶arker-altSri Lanka /envel⌢pehusnasameen016@gmail.com ♂phone-alt750 825 934ὑ7@codenebulax6 /linkedin-infathima-husna/\n",
      "/githubFathimaHusna\n",
      "Summary\n",
      "Highly motivated and detail-oriented AI enthusiast with hands-on experience as an AI Intern, spe-\n",
      "cializing in developing and evaluating machine learning models for real-world applications. Skilled\n",
      "in Python, data preprocessing, model training, and libraries such as Scikit-learn, TensorFlow,\n",
      "and PyTorch. Demonstrated ability to work on NLP, computer vision, and predictive analytics\n",
      "projects. Passionate about solving complex problems through AI-driven solutions and continu-\n",
      "ously learning emerging technologies. Seeking to contribute to innovative AI projects in a dynamic\n",
      "and growth-oriented environment\n",
      "Education\n",
      "University of Moratuwa\n",
      "BSc(Hons) in Information TechnologyJan 2020 – June 2024\n",
      "◦Coursework: Machine Learning, Artificial Neural Networks, Natural Language Processing, Digital Image\n",
      "Processing, Big Data, Data Mining\n",
      "Experience\n",
      "Software Engineer Intern\n",
      "Axiata Digital LabsColombo, Sri Lanka\n",
      "Dec 2022 – June 2023\n",
      "◦Developed and maintained scalable Python-based back-end services, contributing to robust and performant\n",
      "infrastructure supporting various digital solution and Flask, ensuring robust API performance for AI-driven\n",
      "applications.\n",
      "◦Optimized database queries in PostgreSQL and MongoDB, improving data retrieval efficiency by 60% for\n",
      "high-traffic system\n",
      "◦Implemented RESTful APIs to support seamless integration of machine learning models, enhancing appli-\n",
      "cation functionality.\n",
      "◦Collaborated in an Agile environment to deploy Dockerized microservices on AWS, streamlining CI/CD\n",
      "pipelines.\n",
      "Publications\n",
      "Transformers Series /external-link-alt May 2025\n",
      "Part 2: Understanding Self-Attention: The Key to Modern Language Models Like GPT /external-link-alt\n",
      "Projects\n",
      "Telecom Support Chatbot with GraphRAGFathimaHusna/TelecomRagbot\n",
      "/external-link-alt\n",
      "◦Architected and developed an advanced LLM-native Retrieval-Augmented Generation (RAG) system for\n",
      "telecom support, leveraging Ollama LLM with graph-based retrieval and vector similarity search. Focused\n",
      "on designing an efficient workflow for context-sensitive information retrieval, effectively treating the LLM\n",
      "as a collaborator to provide accurate and timely support.\n",
      "◦Tools used: Ollama, GraphRAG, Vector Search, NLP\n",
      "Simple RAG Chatbot\n",
      "github.com/FathimaHusna/ragchatbot\n",
      "/external-link-alt\n",
      "◦Engineered a Retrieval-Augmented Generation (RAG) chatbot utilizing LangChain for orchestration of LLM\n",
      "Husna- Page 1 of 2Last updated in June 2025\n",
      "interactions and OpenAI API. Designed the retrieval workflow by integrating a Pinecone vector store for\n",
      "efficient knowledge retrieval, showcasing experience in building robust LLM-driven systems.\n",
      "◦Tools used: LangChain, OpenAI API, Pinecone, RAG\n",
      "Upwork Profile Enhancing Agent\n",
      "github.com/FathimaHusna/DRAgent\n",
      "/external-link-alt\n",
      "◦Designed and implemented an agent-based system to automate the generation of SEO-optimized Upwork\n",
      "profiles, demonstrating expertise in LLM-native development and orchestration of AI components. The\n",
      "system leveraged AI-driven insights from user input and trending keywords via a specialized ’Deep Research\n",
      "Agent’ (acting as a tool). Orchestrated the Gemini model as a collaborator to produce structured JSON\n",
      "profiles (validated with Pydantic) and scored for tone, SEO, and appeal. This project showcases the ability\n",
      "to build self-improving software agents that translate high-level intent into working, validated outputs.\n",
      "◦Tools used: Python, Gemini, Pydantic, Flask, Google Search API, JSON, HTML/CSS,\n",
      "JavaScript\n",
      "Technologies\n",
      "AI/ML Expertise: LLMs (OpenAI, Gemini, Ollama), NLP, RAG, Prompt Engineering, Agentic Systems\n",
      "Languages Frameworks: Python, JavaScript, Flask, LangChain, TensorFlow, PyTorch, scikit-learn\n",
      "Vector Search Databases: Pinecone, FAISS, PostgreSQL, MongoDB\n",
      "Cloud MLOps: AWS (EC2, S3, Docker), CI/CD Pipelines, RESTful APIs, Docker, Git\n",
      "Tools: VSCode, Jupyter, Postman, GitHub Actions, Linux\n",
      "Husna- Page 2 of 2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Simulate a text file\n",
    "sample_resume_text = \"\"\"\n",
    "John Doe\n",
    "john.doe@email.com\n",
    "(123) 456-7890\n",
    "San Francisco, CA\n",
    "Summary: Experienced software engineer with 5 years in Python and Java development.\n",
    "Education: B.S. Computer Science, Stanford University\n",
    "Technical Skills: Python, Java, SQL, Docker\n",
    "Soft Skills: Communication, Teamwork\n",
    "Work Experience: Software Engineer at Tech Corp, Developed web applications\n",
    "Certifications: AWS Certified Developer\n",
    "\"\"\"\n",
    "\n",
    "# Test text extraction\n",
    "from io import BytesIO\n",
    "\n",
    "# Simulate a TXT file\n",
    "# txt_file = BytesIO(sample_resume_text.encode('utf-8'))\n",
    "# resume_text = ResumeProcessor.extract_text_from_txt(txt_file)\n",
    "# print(\"Extracted Resume Text:\")\n",
    "# print(resume_text)\n",
    "\n",
    "# Optionally, test PDF or DOCX extraction with actual files\n",
    "# Example for PDF (requires a real PDF file):\n",
    "with open(\"experiments/Husna_intern.pdf\", \"rb\") as pdf_file:\n",
    "    resume_text = ResumeProcessor.extract_text_from_pdf(pdf_file)\n",
    "    print(resume_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0597fb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAGJobMatcher:\n",
    "    \"\"\"RAG-based job matching system\"\"\"\n",
    "    \n",
    "    def __init__(self, openai_api_key: str, mongo_uri: str, database_name: str):\n",
    "        \"\"\"Initialize the RAG job matcher\"\"\"\n",
    "        self.client = openai.OpenAI(api_key=openai_api_key)\n",
    "        self.mongo_client = MongoClient(mongo_uri)\n",
    "        self.db = self.mongo_client[database_name]\n",
    "        self.collection = self.db.job_descriptions\n",
    "        \n",
    "        # Initialize TF-IDF vectorizer for similarity matching\n",
    "        self.vectorizer = TfidfVectorizer(\n",
    "            stop_words='english',\n",
    "            max_features=5000,\n",
    "            ngram_range=(1, 3),\n",
    "            lowercase=True\n",
    "        )\n",
    "        self.job_vectors = None\n",
    "        self.job_documents = []\n",
    "        \n",
    "    def load_and_vectorize_jobs(self):\n",
    "        \"\"\"Load jobs from MongoDB and create TF-IDF vectors\"\"\"\n",
    "        try:\n",
    "            # Fetch all jobs from MongoDB\n",
    "            jobs = list(self.collection.find({}, {\"_id\": 0}))\n",
    "            \n",
    "            if not jobs:\n",
    "                st.error(\"No jobs found in database. Please run Task 2 first.\")\n",
    "                return False\n",
    "            \n",
    "            # Create text documents for vectorization\n",
    "            self.job_documents = []\n",
    "            for job in jobs:\n",
    "                # Combine relevant fields for matching\n",
    "                job_text = f\"\"\"\n",
    "                {job.get('title', '')} {job.get('category', '')} \n",
    "                {' '.join(job.get('technical_skills', []))} \n",
    "                {' '.join(job.get('soft_skills', []))} \n",
    "                {' '.join(job.get('responsibilities', []))} \n",
    "                {' '.join(job.get('keywords', []))}\n",
    "                {job.get('job_summary', '')}\n",
    "                \"\"\".strip()\n",
    "                \n",
    "                self.job_documents.append({\n",
    "                    'job_data': job,\n",
    "                    'text': job_text\n",
    "                })\n",
    "            \n",
    "            # Create TF-IDF vectors\n",
    "            job_texts = [doc['text'] for doc in self.job_documents]\n",
    "            self.job_vectors = self.vectorizer.fit_transform(job_texts)\n",
    "            \n",
    "            logger.info(f\"Loaded and vectorized {len(jobs)} jobs\")\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error loading jobs: {e}\")\n",
    "            st.error(f\"Error loading jobs from database: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def process_resume_with_llm(self, resume_text: str) -> Optional[ProcessedResume]:\n",
    "        \"\"\"Process resume using LLM to extract structured information\"\"\"\n",
    "        try:\n",
    "            prompt = f\"\"\"\n",
    "            Analyze the following resume and extract structured information. \n",
    "            Return the information in JSON format with the following exact keys:\n",
    "\n",
    "            Resume Text:\n",
    "            {resume_text}\n",
    "\n",
    "            Extract and return JSON with these keys:\n",
    "            {{\n",
    "                \"name\": \"full name of the person\",\n",
    "                \"email\": \"email address\",\n",
    "                \"phone\": \"phone number\",\n",
    "                \"location\": \"city, state or location\",\n",
    "                \"summary\": \"professional summary or objective\",\n",
    "                \"experience_years\": \"total years of experience or estimate\",\n",
    "                \"education\": [\"degree\", \"university\", \"certifications\"],\n",
    "                \"technical_skills\": [\"programming languages\", \"tools\", \"technologies\"],\n",
    "                \"soft_skills\": [\"communication\", \"leadership\", \"teamwork\"],\n",
    "                \"work_experience\": [\"job titles\", \"companies\", \"key achievements\"],\n",
    "                \"certifications\": [\"professional certifications\", \"licenses\"],\n",
    "                \"keywords\": [\"relevant keywords for job matching\"]\n",
    "            }}\n",
    "\n",
    "            Guidelines:\n",
    "            - Extract only information that is explicitly mentioned\n",
    "            - For technical_skills, focus on hard skills, tools, and technologies\n",
    "            - For keywords, include important terms that would help in job matching\n",
    "            - If information is not available, use empty array [] or \"Not specified\"\n",
    "            - Return only valid JSON, no additional text\n",
    "            \"\"\"\n",
    "            \n",
    "            response = self.client.chat.completions.create(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are an expert resume parser. Extract structured information and return only valid JSON.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                max_tokens=1500,\n",
    "                temperature=0.3\n",
    "            )\n",
    "            \n",
    "            # Parse the response\n",
    "            extracted_text = response.choices[0].message.content.strip()\n",
    "            \n",
    "            # Clean JSON response\n",
    "            start_idx = extracted_text.find('{')\n",
    "            end_idx = extracted_text.rfind('}')\n",
    "            if start_idx != -1 and end_idx != -1:\n",
    "                extracted_text = extracted_text[start_idx:end_idx + 1]\n",
    "            \n",
    "            extracted_data = json.loads(extracted_text)\n",
    "            \n",
    "            # Create ProcessedResume object\n",
    "            processed_resume = ProcessedResume(\n",
    "                name=extracted_data.get('name', 'Not specified'),\n",
    "                email=extracted_data.get('email', 'Not specified'),\n",
    "                phone=extracted_data.get('phone', 'Not specified'),\n",
    "                location=extracted_data.get('location', 'Not specified'),\n",
    "                summary=extracted_data.get('summary', ''),\n",
    "                experience_years=extracted_data.get('experience_years', 'Not specified'),\n",
    "                education=extracted_data.get('education', []),\n",
    "                technical_skills=extracted_data.get('technical_skills', []),\n",
    "                soft_skills=extracted_data.get('soft_skills', []),\n",
    "                work_experience=extracted_data.get('work_experience', []),\n",
    "                certifications=extracted_data.get('certifications', []),\n",
    "                keywords=extracted_data.get('keywords', []),\n",
    "                resume_text=resume_text,\n",
    "                processed_at=datetime.now().isoformat()\n",
    "            )\n",
    "            \n",
    "            return processed_resume\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error processing resume with LLM: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def find_matching_jobs(self, processed_resume: ProcessedResume, top_k: int = 10) -> List[JobMatch]:\n",
    "        \"\"\"Find matching jobs using RAG approach\"\"\"\n",
    "        try:\n",
    "            if self.job_vectors is None:\n",
    "                if not self.load_and_vectorize_jobs():\n",
    "                    return []\n",
    "            \n",
    "            # Create resume text for similarity matching\n",
    "            resume_text = f\"\"\"\n",
    "            {processed_resume.summary}\n",
    "            {' '.join(processed_resume.technical_skills)}\n",
    "            {' '.join(processed_resume.soft_skills)}\n",
    "            {' '.join(processed_resume.work_experience)}\n",
    "            {' '.join(processed_resume.keywords)}\n",
    "            \"\"\"\n",
    "            \n",
    "            # Vectorize resume\n",
    "            resume_vector = self.vectorizer.transform([resume_text])\n",
    "            \n",
    "            # Calculate cosine similarity\n",
    "            similarities = cosine_similarity(resume_vector, self.job_vectors).flatten()\n",
    "            \n",
    "            # Get top matches\n",
    "            top_indices = np.argsort(similarities)[::-1][:top_k]\n",
    "            \n",
    "            matches = []\n",
    "            for idx in top_indices:\n",
    "                job_data = self.job_documents[idx]['job_data']\n",
    "                similarity_score = similarities[idx]\n",
    "                \n",
    "                # Calculate matching and missing skills\n",
    "                resume_skills = set([skill.lower() for skill in processed_resume.technical_skills])\n",
    "                job_skills = set([skill.lower() for skill in job_data.get('technical_skills', [])])\n",
    "                \n",
    "                matching_skills = list(resume_skills.intersection(job_skills))\n",
    "                missing_skills = list(job_skills.difference(resume_skills))\n",
    "                \n",
    "                # Generate match reasons\n",
    "                match_reasons = self._generate_match_reasons(\n",
    "                    processed_resume, job_data, similarity_score, matching_skills\n",
    "                )\n",
    "                \n",
    "                match = JobMatch(\n",
    "                    job_id=job_data.get('job_id', ''),\n",
    "                    title=job_data.get('title', ''),\n",
    "                    category=job_data.get('category', ''),\n",
    "                    company_type=job_data.get('company_type', ''),\n",
    "                    location=job_data.get('location', ''),\n",
    "                    similarity_score=similarity_score,\n",
    "                    matching_skills=matching_skills,\n",
    "                    missing_skills=missing_skills[:5],  # Top 5 missing skills\n",
    "                    job_summary=job_data.get('job_summary', ''),\n",
    "                    salary_range=job_data.get('salary_range', 'Not specified'),\n",
    "                    match_reasons=match_reasons\n",
    "                )\n",
    "                \n",
    "                matches.append(match)\n",
    "            \n",
    "            return matches\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error finding matching jobs: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def _generate_match_reasons(self, resume: ProcessedResume, job: Dict, \n",
    "                              similarity_score: float, matching_skills: List[str]) -> List[str]:\n",
    "        \"\"\"Generate human-readable match reasons\"\"\"\n",
    "        reasons = []\n",
    "        \n",
    "        # Similarity score reason\n",
    "        if similarity_score > 0.3:\n",
    "            reasons.append(f\"High compatibility score ({similarity_score:.2%})\")\n",
    "        \n",
    "        # Skill matches\n",
    "        if matching_skills:\n",
    "            skill_str = ', '.join(matching_skills[:3])\n",
    "            reasons.append(f\"Matching skills: {skill_str}\")\n",
    "        \n",
    "        # Category match\n",
    "        resume_keywords = [kw.lower() for kw in resume.keywords]\n",
    "        job_category = job.get('category', '').lower()\n",
    "        if any(keyword in job_category for keyword in resume_keywords):\n",
    "            reasons.append(f\"Relevant experience in {job.get('category', '')}\")\n",
    "        \n",
    "        # Location preference\n",
    "        if resume.location.lower() in job.get('location', '').lower():\n",
    "            reasons.append(\"Location preference match\")\n",
    "        \n",
    "        return reasons[:4]  # Return top 4 reasons\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b43066d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f7ce7864",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Loaded and vectorized 2 jobs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Resume:\n",
      "ProcessedResume(name='John Doe', email='john.doe@email.com', phone='(123) 456-7890', location='San Francisco, CA', summary='Experienced software engineer with 5 years in Python and Java development.', experience_years='5 years', education=['B.S. Computer Science, Stanford University'], technical_skills=['Python', 'Java', 'SQL', 'Docker'], soft_skills=['Communication', 'Teamwork'], work_experience=['Software Engineer at Tech Corp, Developed web applications'], certifications=['AWS Certified Developer'], keywords=['software engineer', 'Python', 'Java', 'web development'], resume_text='\\nJohn Doe\\njohn.doe@email.com\\n(123) 456-7890\\nSan Francisco, CA\\nSummary: Experienced software engineer with 5 years in Python and Java development.\\nEducation: B.S. Computer Science, Stanford University\\nTechnical Skills: Python, Java, SQL, Docker\\nSoft Skills: Communication, Teamwork\\nWork Experience: Software Engineer at Tech Corp, Developed web applications\\nCertifications: AWS Certified Developer\\n', processed_at='2025-07-26T08:23:34.385636')\n",
      "\n",
      "Job Matches:\n",
      "Title: Senior Software Engineer, Score: 56.97%\n",
      "Matching Skills: ['java', 'python']\n",
      "Missing Skills: ['aws']\n",
      "Match Reasons: ['High compatibility score (56.97%)', 'Matching skills: java, python', 'Location preference match']\n",
      "---\n",
      "Title: Data Scientist, Score: 4.55%\n",
      "Matching Skills: ['python']\n",
      "Missing Skills: ['tensorflow', 'r']\n",
      "Match Reasons: ['Matching skills: python']\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Mock OpenAI API response\n",
    "class MockOpenAIResponse:\n",
    "    def __init__(self):\n",
    "        self.choices = [MockChoice()]\n",
    "\n",
    "class MockChoice:\n",
    "    def __init__(self):\n",
    "        self.message = MockMessage()\n",
    "\n",
    "class MockMessage:\n",
    "    def __init__(self):\n",
    "        self.content = json.dumps({\n",
    "            \"name\": \"John Doe\",\n",
    "            \"email\": \"john.doe@email.com\",\n",
    "            \"phone\": \"(123) 456-7890\",\n",
    "            \"location\": \"San Francisco, CA\",\n",
    "            \"summary\": \"Experienced software engineer with 5 years in Python and Java development.\",\n",
    "            \"experience_years\": \"5 years\",\n",
    "            \"education\": [\"B.S. Computer Science, Stanford University\"],\n",
    "            \"technical_skills\": [\"Python\", \"Java\", \"SQL\", \"Docker\"],\n",
    "            \"soft_skills\": [\"Communication\", \"Teamwork\"],\n",
    "            \"work_experience\": [\"Software Engineer at Tech Corp, Developed web applications\"],\n",
    "            \"certifications\": [\"AWS Certified Developer\"],\n",
    "            \"keywords\": [\"software engineer\", \"Python\", \"Java\", \"web development\"]\n",
    "        })\n",
    "\n",
    "# Mock OpenAI client (correct version)\n",
    "class MockOpenAI:\n",
    "    def __init__(self, api_key):\n",
    "        self.chat = MockChat()\n",
    "\n",
    "class MockChat:\n",
    "    def __init__(self):\n",
    "        self.completions = MockCompletions()\n",
    "\n",
    "class MockCompletions:\n",
    "    def create(self, model, messages, max_tokens, temperature):\n",
    "        return MockOpenAIResponse()\n",
    "\n",
    "# Mock MongoDB collection\n",
    "sample_jobs = [\n",
    "    {\n",
    "        \"job_id\": \"1\",\n",
    "        \"title\": \"Senior Software Engineer\",\n",
    "        \"category\": \"Software Development\",\n",
    "        \"company_type\": \"Tech Startup\",\n",
    "        \"location\": \"San Francisco, CA\",\n",
    "        \"technical_skills\": [\"Python\", \"Java\", \"AWS\"],\n",
    "        \"soft_skills\": [\"Leadership\", \"Communication\"],\n",
    "        \"responsibilities\": [\"Develop web applications\", \"Lead team\"],\n",
    "        \"keywords\": [\"software engineer\", \"Python\", \"AWS\"],\n",
    "        \"job_summary\": \"Develop and maintain web applications using Python and AWS.\",\n",
    "        \"salary_range\": \"$120,000 - $150,000\"\n",
    "    },\n",
    "    {\n",
    "        \"job_id\": \"2\",\n",
    "        \"title\": \"Data Scientist\",\n",
    "        \"category\": \"Data Science\",\n",
    "        \"company_type\": \"Enterprise\",\n",
    "        \"location\": \"New York, NY\",\n",
    "        \"technical_skills\": [\"Python\", \"R\", \"TensorFlow\"],\n",
    "        \"soft_skills\": [\"Problem-solving\", \"Communication\"],\n",
    "        \"responsibilities\": [\"Analyze data\", \"Build ML models\"],\n",
    "        \"keywords\": [\"data scientist\", \"Python\", \"machine learning\"],\n",
    "        \"job_summary\": \"Build and deploy machine learning models.\",\n",
    "        \"salary_range\": \"$100,000 - $130,000\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Mock MongoDB client\n",
    "class MockMongoCollection:\n",
    "    def find(self, query, projection):\n",
    "        return sample_jobs\n",
    "\n",
    "class MockMongoDB:\n",
    "    def __init__(self, uri):\n",
    "        self.db = MockDB()\n",
    "    \n",
    "    def __getitem__(self, name):\n",
    "        return self.db\n",
    "\n",
    "class MockDB:\n",
    "    def __init__(self):\n",
    "        self.job_descriptions = MockMongoCollection()\n",
    "\n",
    "# Override RAGJobMatcher to use mocks\n",
    "class TestRAGJobMatcher(RAGJobMatcher):\n",
    "    def __init__(self):\n",
    "        self.client = MockOpenAI(\"dummy_key\")\n",
    "        self.mongo_client = MockMongoDB(\"dummy_uri\")\n",
    "        self.db = self.mongo_client[\"recruitment_platform\"]\n",
    "        self.collection = self.db.job_descriptions\n",
    "        self.vectorizer = TfidfVectorizer(\n",
    "            stop_words='english',\n",
    "            max_features=5000,\n",
    "            ngram_range=(1, 3),\n",
    "            lowercase=True\n",
    "        )\n",
    "        self.job_vectors = None\n",
    "        self.job_documents = []\n",
    "\n",
    "# Sample resume text\n",
    "sample_resume_text = \"\"\"\n",
    "John Doe\n",
    "john.doe@email.com\n",
    "(123) 456-7890\n",
    "San Francisco, CA\n",
    "Summary: Experienced software engineer with 5 years in Python and Java development.\n",
    "Education: B.S. Computer Science, Stanford University\n",
    "Technical Skills: Python, Java, SQL, Docker\n",
    "Soft Skills: Communication, Teamwork\n",
    "Work Experience: Software Engineer at Tech Corp, Developed web applications\n",
    "Certifications: AWS Certified Developer\n",
    "\"\"\"\n",
    "\n",
    "# Test RAGJobMatcher\n",
    "matcher = TestRAGJobMatcher()\n",
    "\n",
    "# Process resume\n",
    "processed_resume = matcher.process_resume_with_llm(sample_resume_text)\n",
    "print(\"Processed Resume:\")\n",
    "print(processed_resume)\n",
    "\n",
    "# Load and vectorize jobs\n",
    "matcher.load_and_vectorize_jobs()\n",
    "\n",
    "# Find matching jobs\n",
    "job_matches = matcher.find_matching_jobs(processed_resume, top_k=2)\n",
    "print(\"\\nJob Matches:\")\n",
    "for match in job_matches:\n",
    "    print(f\"Title: {match.title}, Score: {match.similarity_score:.2%}\")\n",
    "    print(f\"Matching Skills: {match.matching_skills}\")\n",
    "    print(f\"Missing Skills: {match.missing_skills}\")\n",
    "    print(f\"Match Reasons: {match.match_reasons}\")\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5ddd8838",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReportGenerator:\n",
    "    \"\"\"Generate PDF and CSV reports\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def generate_pdf_report(matches: List[JobMatch], resume_name: str) -> bytes:\n",
    "        \"\"\"Generate PDF report of job matches\"\"\"\n",
    "        buffer = io.BytesIO()\n",
    "        doc = SimpleDocTemplate(buffer, pagesize=letter)\n",
    "        styles = getSampleStyleSheet()\n",
    "        story = []\n",
    "        \n",
    "        # Title\n",
    "        title_style = ParagraphStyle(\n",
    "            'CustomTitle',\n",
    "            parent=styles['Heading1'],\n",
    "            fontSize=18,\n",
    "            spaceAfter=30,\n",
    "            textColor=colors.darkblue\n",
    "        )\n",
    "        story.append(Paragraph(f\"Job Recommendations for {resume_name}\", title_style))\n",
    "        story.append(Spacer(1, 20))\n",
    "        \n",
    "        # Summary\n",
    "        summary_text = f\"Generated on: {datetime.now().strftime('%B %d, %Y')}<br/>Total Matches: {len(matches)}\"\n",
    "        story.append(Paragraph(summary_text, styles['Normal']))\n",
    "        story.append(Spacer(1, 20))\n",
    "        \n",
    "        # Job matches\n",
    "        for i, match in enumerate(matches, 1):\n",
    "            # Job header\n",
    "            job_header = f\"{i}. {match.title} - {match.company_type}\"\n",
    "            story.append(Paragraph(job_header, styles['Heading2']))\n",
    "            \n",
    "            # Job details\n",
    "            details = f\"\"\"\n",
    "            <b>Category:</b> {match.category}<br/>\n",
    "            <b>Location:</b> {match.location}<br/>\n",
    "            <b>Compatibility:</b> {match.similarity_score:.1%}<br/>\n",
    "            <b>Salary Range:</b> {match.salary_range}<br/>\n",
    "            \"\"\"\n",
    "            story.append(Paragraph(details, styles['Normal']))\n",
    "            \n",
    "            # Match reasons\n",
    "            if match.match_reasons:\n",
    "                reasons_text = \"<b>Why this matches:</b><br/>\" + \"<br/>\".join([f\"• {reason}\" for reason in match.match_reasons])\n",
    "                story.append(Paragraph(reasons_text, styles['Normal']))\n",
    "            \n",
    "            # Skills\n",
    "            if match.matching_skills:\n",
    "                skills_text = f\"<b>Matching Skills:</b> {', '.join(match.matching_skills[:5])}\"\n",
    "                story.append(Paragraph(skills_text, styles['Normal']))\n",
    "            \n",
    "            story.append(Spacer(1, 15))\n",
    "        \n",
    "        doc.build(story)\n",
    "        buffer.seek(0)\n",
    "        return buffer.getvalue()\n",
    "    \n",
    "    @staticmethod\n",
    "    def generate_csv_report(matches: List[JobMatch]) -> str:\n",
    "        \"\"\"Generate CSV report of job matches\"\"\"\n",
    "        data = []\n",
    "        for match in matches:\n",
    "            data.append({\n",
    "                'Job Title': match.title,\n",
    "                'Category': match.category,\n",
    "                'Company Type': match.company_type,\n",
    "                'Location': match.location,\n",
    "                'Compatibility Score': f\"{match.similarity_score:.1%}\",\n",
    "                'Salary Range': match.salary_range,\n",
    "                'Matching Skills': '; '.join(match.matching_skills),\n",
    "                'Missing Skills': '; '.join(match.missing_skills),\n",
    "                'Match Reasons': '; '.join(match.match_reasons),\n",
    "                'Job Summary': match.job_summary[:200] + '...' if len(match.job_summary) > 200 else match.job_summary\n",
    "            })\n",
    "        \n",
    "        df = pd.DataFrame(data)\n",
    "        return df.to_csv(index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "447ae762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF report generated: job_matches.pdf\n",
      "CSV report generated: job_matches.csv\n"
     ]
    }
   ],
   "source": [
    "# Test ReportGenerator\n",
    "pdf_data = ReportGenerator.generate_pdf_report(job_matches, \"John Doe\")\n",
    "with open(\"job_matches.pdf\", \"wb\") as f:\n",
    "    f.write(pdf_data)\n",
    "print(\"PDF report generated: job_matches.pdf\")\n",
    "\n",
    "csv_data = ReportGenerator.generate_csv_report(job_matches)\n",
    "with open(\"job_matches.csv\", \"w\") as f:\n",
    "    f.write(csv_data)\n",
    "print(\"CSV report generated: job_matches.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016b54ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f185a2df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:OPENAI_API_KEY: set\n",
      "INFO:__main__:MONGO_URI: set\n",
      "INFO:__main__:DATABASE_NAME: recruitment_platform\n",
      "INFO:__main__:Successfully connected to MongoDB!\n",
      "INFO:__main__:Databases: ['recruitment_platform', 'admin', 'local']\n"
     ]
    }
   ],
   "source": [
    "# for testing the MongoDB connection\n",
    "from pymongo import MongoClient\n",
    "from pymongo.server_api import ServerApi\n",
    "import certifi\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "mongo_uri = os.getenv(\"MONGO_URI\")\n",
    "database_name = os.getenv(\"DATABASE_NAME\", \"recruitment_platform\")\n",
    "\n",
    "logger.info(f\"OPENAI_API_KEY: {'set' if openai_api_key else 'not set'}\")\n",
    "logger.info(f\"MONGO_URI: {'set' if mongo_uri else 'not set'}\")\n",
    "logger.info(f\"DATABASE_NAME: {database_name}\")\n",
    "\n",
    "if not openai_api_key or not mongo_uri:\n",
    "    logger.error(\"Missing required credentials.\")\n",
    "    exit(1)\n",
    "\n",
    "client = MongoClient(mongo_uri, server_api=ServerApi('1'), tls=True, tlsCAFile=certifi.where())\n",
    "try:\n",
    "    client.admin.command('ping')\n",
    "    logger.info(\"Successfully connected to MongoDB!\")\n",
    "    databases = client.list_database_names()\n",
    "    logger.info(f\"Databases: {databases}\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error connecting to MongoDB: {e}\")\n",
    "finally:\n",
    "    client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636889aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
